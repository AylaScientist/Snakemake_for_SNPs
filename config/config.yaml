# Please check the parameters, and adjust them according to your circumstance

# Project name
PROJECT: test

# ================== Control of the workflow ==================

# Provide with these files in order to proceed with the workflow:
Sample_names: ../config/Sample_names.csv
Experimental_design: ../config/Experimental_design.csv
Experimental_groups: ../config/Experimental_groups.csv
Pseudogenome_codes: ../config/Pseudogenome_codes.csv # after you choose the samples from where you will make the pseudogenomes
GeneID_to_Genebank: ../config/GeneID_to_Genebank.csv
GO_dict: ../config/GO_dictionary.csv
tb1_colnames: ../config/tb1_colnames.csv
tb2_colnames: ../config/tb2_colnames.csv
species_dict: ../config/Tilapia gene transcript protein GO KEGG uniprot.csv
fastq_merged: fastq_merged
Samples_MAE: ../config/Samples_MAE.csv

## Resources of the system:
gpu: 0
#jobs_per_gpu: 6

#Parallel_jobs: Is the total resources divided by the number of samples, 4 in this case
java_opts_parallel: "-XX:MinRAMPercentage=80.0 -Xms25G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=3 -XX:+UseTLAB"
threads_parallel: 3 # that refers to the number of cores. The parallel threads are defined above
mem_mb_parallel: 30000


#Combine: Is total resources divided by two pseudogenomes
java_opts_combine: "-XX:MinRAMPercentage=80.0 -Xms50G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=6 -XX:+UseTLAB"
threads_combine: 6 # that refers to the number of cores. The parallel threads are defined above
mem_mb_combine: 6000

#Reference genome: Total resources for rules that do not have parallel works. 
java_opts: "-XX:MinRAMPercentage=80.0 -Xms100G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=12 -XX:+UseTLAB"
threads: 12 # that refers to the number of cores. The parallel threads are defined above
mem_mb: 120000

# Path to workflow with relation to snakefile. Can vary depending on your HPC configuration
path: "~/AylaScientist/Snakemake_for_SNPs/GitHub/workflow/"

pseudogenomes: # Write the pseudogenomes as they are found in the file ../config/Pseudogenome_codes.csv
  PSG1: "6GF"
  PSG2: "4KS"

input_files: # Add the fastq files of your experiment
  r1: "fastq_merged/{sample}.fastq"
  r2: "fastq_merged/{sample}.fastq" # Optional

results:
  o1: "results/SNPs_function.csv"
  o2: "results/SNP_dictionary.csv"
  o3: "results/Treatment_SNPs_sig_all_for_Venn.csv"
  o4: "results/Summary_of_polymorphisms.csv"
  o5: "results/Intronic_SNPs_caryotype.csv"

results_mae:
  om1: "results/SNPs_function_mae.csv"
  om2: "results/SNP_dictionary_mae.csv"
  om3: "results/Treatment_SNPs_sig_all_for_Venn_mae.csv"
  om4: "results/Summary_of_polymorphisms_mae.csv"
  om5: "results/Intronic_SNPs_caryotype_mae.csv"

files_pseudogenomes:
  PSG_dict: "pseudogenomes/{pseudo}/{pseudo}_GCF_001858045.2.dict"
  PSG_index: "pseudogenomes/{pseudo}/SAindex"
  PSG_fai: "pseudogenomes/{pseudo}/{pseudo}_GCF_001858045.2.fa.fai"

other_intermediate_files: # For bqsr recalibration, in case you have known SNPs
  bam: "recal/{sample}_ref.bam"
  bqsr: recal_tables/{sample}_after_ref.table"
  valid_bqsr: logs/picard/ValidateSamFile/Validate_bqsr_{sample}.log"
  valid_bqsr_PSG: logs/picard/ValidateSamFile_{pseudo}/Validate_bqsr_{sample}_{pseudo}.log"
  recal_table: "recal_tables/{sample}_after_ref.table"

error: "results/Error_in_SNP_calling_valid_genome.csv"

ref:
  # ensembl species name
  species: Nile tilapia
  # ensembl release
  release: GCF_001858045.2
  # genome build
  build: NMBU
  # file name
  genome: "genome/Tilapia_NC_031967.2_GCF_001858045.2.fa"
  annotation: "genome/Tilapia_NC_031967.2_GCF_001858045.2_annotation.gff3"
  gtf: "genome/Tilapia_NC_031967.2_GCF_001858045.2_annotation.gtf"
  SAindex: "genome/SAindex"
  dict: "genome/Tilapia_NC_031967.2_GCF_001858045.2.dict"
  read_length: 89 # Read length - 1

filtering:
  # Set to true in order to apply machine learning based recalibration of
  # quality scores instead of hard filtering.
  vqsr: false
  hard:
    # hard filtering as outlined in GATK docs
    # (https://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set)
    snvs:
      "QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0"
    indels:
      "QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0"

params:
  star:
    read_length: 89 #read lenght -1
    mode: SE #SE for single ends or PE for paired ends
  gatk:
    HaplotypeCaller: ""
    BaseRecalibrator: ""
    GenotypeGVCFs: ""
    VariantRecalibrator: ""
  picard:
    MarkDuplicates: "REMOVE_DUPLICATES=true"
  trimmomatic:
    path: "~/anaconda3/envs/pipeline/share/trimmomatic-0.39-2/trimmomatic.jar" #The path to your .jar trimmomatic
    pe:
      trimmer:
        # See trimmomatic manual for adding additional options, e.g. for adapter trimming.
        #- "ILLUMINACLIP:./resources/TruSeq3-PE-2.fa:2:30:10:2:keepBothReads "
        - "LEADING:3 "
        #- "TRAILING:3 "
        #- "SLIDINGWINDOW:4:15 "
        #- "MINLEN:36 "
    se:
      trimmer:
        # See trimmomatic manual for adding additional options, e.g. for adapter trimming.
        - "LEADING:3 "
        - "TRAILING:3 "
        #- "SLIDINGWINDOW:4:15 "
        - "MINLEN:36 "
  annotation:
    buildver: "ON" # Write here the location of the database refGene.txt with the speces prefix (ON Oreochromis nilotius)
    path: "ON/"
    pathbuild: "ON/ON"
    o1: "annotated/annotated_all_snps_{pseudo}.ON_multianno.vcf" # Change the prefix by the one in the database of the annotation, defined just in the line above
    extra: "-SMA TRUE -F CHROM -F POS -F Gene.refGene -F Func.refGene -F ExonicFunc.refGene -F AF -GF AD -GF GT" #Parameters to take
    #Change the name of the example species (Nile) into your studied species
    convert: "annotated/annovar_Nile_{pseudo}"
    output_token: "annotated/annotated_Nile_snps_{pseudo}"
    output_annotate: "annotated/annotated_Nile_snps_{pseudo}.variant_function"
  
  var2table: "pseudogenomes/{pseudo}/{pseudo}_GCF_001858045.2.fa"