# Please check the parameters, and adjust them according to your circumstance

# Project name
PROJECT: test 0 false positives in call

# ================== Control of the workflow ==================

# Provide with these files in order to proceed with the workflow:
Sample_names: ../config/Sample_names.csv
Experimental_design: ../config/Experimental_design.csv
Experimental_groups: ../config/Experimental_groups.csv
Experimental_factor: Error_002 #For calculating the allele frequencies of the groups according to it, rule QC
Pseudogenome_codes: ../config/Pseudogenome_codes.csv # after you choose the samples from where you will make the pseudogenomes
GeneID_to_Genebank: ../config/geneID_to_genebank_human.tsv
GO_dict: ../config/Tilapia gene transcript protein GO KEGG uniprot.csv
tb1_colnames: ../config/tb1_colnames.csv
tb2_colnames: ../config/tb2_colnames.csv
Tilapia_dict: ../config/Tilapia gene transcript protein GO KEGG uniprot.csv
fastq_merged: fastq_merged/
end_fastq_1: _1.fastq
end_fastq_2: _2.fastq
mae: ../config/Samples_MAE.csv


## Resources of the system:
java_opts: -XX:MinRAMPercentage=80.0 -Xms800G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=4 -XX:+UseTLAB
threads: 4
mem_mb: 900000
gpu: 1

# Resources for mapping against the reference genome (recommended 1/4th)
java_opts_ref: -XX:MinRAMPercentage=80.0 -Xms300G -Xmx350G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=2 -XX:+UseTLAB
threads_ref: 2
mem_mb_ref: 400000

# Resources for mapping against the pseudogenomes (recommended 1/4th)
java_opts_pseudo: -XX:MinRAMPercentage=80.0 -Xms300G -Xmx350G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=2 -XX:+UseTLAB
threads_pseudo: 2
mem_mb_pseudo: 400000

# Resources for combination of vcf.g files, including annotation (recommended 1/2)
java_opts_combine: -XX:MinRAMPercentage=80.0 -Xms800G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=4 -XX:+UseTLAB
threads_combine: 4
mem_mb_combine: 900000

# Resources for genome indexer (recommended 1/2)
java_opts_gi: -XX:MinRAMPercentage=80.0 -Xms800G -XX:-UseConcMarkSweepGC -XX:ParallelGCThreads=4 -XX:+UseTLAB
threads_gi: 4
mem_mb_gi: 900000



path: /home/ARO.local/aurorac/Projects/Simulation/workflow/

results:
  o1: results/SNPs_function.csv
  o2: results/SNP_dictionary.csv
  o3: results/Treatment_SNPs_sig_all_for_Venn.csv
  o4: results/Summary_of_polymorphisms.csv
  o5: results/Intronic_SNPs_caryotype.csv

# Reference genome
ref:
  # ensembl species name
  species: Human
  # ensembl release
  release: GCF_000001405.26
  # genome build
  build: hg38
  # file name and paths
  genome: genome/Homo_sapiens.GRCh38.dna.toplevel.fa
  dict: genome/Homo_sapiens.GRCh38.dna.toplevel.dict
  annotation: genome/Homo_sapiens.GRCh38.107.chr.gtf
  annotation_refseq: genome/Homo_sapiens.GRCh38.107.chr.gff3 #genome/Homo_sapiens.GRCh38.Entrez_annotation.gff
  gtf: genome/Homo_sapiens.GRCh38.107.chr.gtf
  SAindex: genome/SAindex
  read_length: 150



filtering:
  # Set to true in order to apply machine learning based recalibration of
  # quality scores instead of hard filtering.
  vqsr: false
  hard:
    # hard filtering as outlined in GATK docs
    # (https://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set)
    snvs:
      "QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0"
    indels:
      "QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0"

processing:
  remove-duplicates: false
  # Uncomment and point to a bed file with, e.g., captured regions if necessary,
  # see https://gatkforums.broadinstitute.org/gatk/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals.
  # restrict-regions: captured_regions.bed
  # If regions are restricted, uncomment this to enlarge them by the given value in order to include
  # flanking areas.
  # region-padding: 100

# Parametres of the different rules
params:
  star:
    threads_gi: 4
    threads_map: 1
    read_length: 149 # read length -1
  gatk:
    HaplotypeCaller: ""
    BaseRecalibrator: ""
    GenotypeGVCFs: ""
    VariantRecalibrator: ""
  picard:
    MarkDuplicates: "REMOVE_DUPLICATES=false"
  trimmomatic:
    path: /data/bin/miniconda2/envs/trimmomatic-v038/share/trimmomatic-0.38-1/trimmomatic.jar #/home/ayla/anaconda3/envs/snakemake/share/trimmomatic-0.39-2/trimmomatic.jar
    pe:
      trimmer:
        # See trimmomatic manual for adding additional options, e.g. for adapter trimming.
        - "ILLUMINACLIP:../resources/TruSeq3-PE-2.fa:2:30:10:2:keepBothReads "
        - "LEADING:3 "
        - "TRAILING:3 "
        - "SLIDINGWINDOW:4:15 "
        - "MINLEN:36"

    se:
      trimmer:
        # See trimmomatic manual for adding additional options, e.g. for adapter trimming.
        - "LEADING:3"
        - "TRAILING:3"
        - "SLIDINGWINDOW:4:15"
        - "MINLEN:36"
  vep:
    plugins:
      # Add any plugin from https://www.ensembl.org/info/docs/tools/vep/script/vep_plugins.html
      # Plugin args can be passed as well, e.g. "LoFtool,path/to/custom/scores.txt".
      - LoFtool
    # extra command line arguments (e.g. --sift, see docs)
    extra: ""
